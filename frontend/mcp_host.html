<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Host with MCP clients</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <!-- Model selector dropdown -->
  <div class="model-selector">
    <span class="model-label">Model:</span>
    <select id="modelSelector">
      <option value="loading">Loading models...</option>
    </select>
  </div>

  <!-- Tools toggle switch -->
  <div class="toggle-container">
    <span class="toggle-label">Tools:</span>
    <label class="switch">
      <input type="checkbox" id="toolsToggle" checked>
      <span class="slider"></span>
    </label>
    <span class="tool-status" id="toolStatus">ON</span>
  </div>

  <!-- Title indicates the single LLM in use -->
  <h2>Host with MCP clients</h2>
  
  <!-- Input box for user messages -->
  <input type="text" id="userInput" placeholder="Type a message and press Enter..." />

  <!-- Container for the single response panel -->
  <div id="chatbox">
    <div class="chat-container">
      <h3 id="modelTitle">Waiting for input...</h3>
      <pre id="response">Type a message and press Enter to begin.</pre>
    </div>
  </div>
  
  <script>
      let toolsEnabled = true; // Default to enabled
      let model = null; // Don't hardcode - will be set by fetchAvailableModels()
      
      // Fetch available models when page loads
      document.addEventListener('DOMContentLoaded', fetchAvailableModels);
      
      // Fetch available models from Ollama
      async function fetchAvailableModels() {
        try {
          const response = await fetch("http://localhost:11434/api/tags");
          
          if (!response.ok) {
            throw new Error("Failed to fetch models");
          }
          
          const data = await response.json();
          const models = data.models || [];
          
          // Populate the dropdown
          const selector = document.getElementById("modelSelector");
          selector.innerHTML = ""; // Clear the loading option
          
          models.forEach(modelInfo => {
            const option = document.createElement("option");
            option.value = modelInfo.name;
            option.textContent = modelInfo.name;
            selector.appendChild(option);
          });
          
          // Set default model if available (use first available model)
          if (models.length > 0) {
            const defaultModel = models[0];
            model = { id: defaultModel.name, displayName: defaultModel.name };
            selector.value = defaultModel.name; // Set the dropdown to show this model
            updateModelTitle("LLM");
          } else {
            // No models available
            model = null;
            selector.innerHTML = '<option value="">No models available</option>';
          }
        } catch (error) {
          console.error("Error fetching models:", error);
          document.getElementById("modelSelector").innerHTML = 
            '<option value="error">Error loading models</option>';
          model = null;
        }
      }

      // Update the title with the response source (add safety check)
      function updateModelTitle(source, toolName = null) {
        if (source === "Tool" && toolName) {
          document.getElementById("modelTitle").textContent = `Response from Tool: ${toolName}`;
        } else if (source === "LLM" && model) {
          document.getElementById("modelTitle").textContent = `Response from LLM: ${model.displayName}`;
        } else {
          document.getElementById("modelTitle").textContent = `Response from ${source}`;
        }
      }

      // Model selector event listener
      document.getElementById("modelSelector").addEventListener("change", function() {
        const selectedModel = this.value;
        model = { id: selectedModel, displayName: selectedModel };
        // Only update the title if we're currently showing an LLM response
        if (document.getElementById("modelTitle").textContent.includes("LLM")) {
          updateModelTitle("LLM");
        }
      });

      // Toggle tools functionality
      document.getElementById("toolsToggle").addEventListener("change", function() {
        toolsEnabled = this.checked;
        document.getElementById("toolStatus").innerText = toolsEnabled ? "ON" : "OFF";
      });

      document.getElementById("userInput").addEventListener("keypress", function(event) {
        if (event.key === "Enter") {
          event.preventDefault();
          sendMessage();
        }
      });

      // Add safety check to sendMessage function
      async function sendMessage() {
        const inputField = document.getElementById("userInput");
        const userMessage = inputField.value.trim();
        if (userMessage === "") return;

        // Check if model is available
        if (!model || !model.id) {
          document.getElementById("response").innerText = "Error: No model selected or available";
          updateModelTitle("Error");
          return;
        }

        document.getElementById("response").innerText = "Loading...";
        updateModelTitle("Processing");

        try {
          // Only attempt tool routing if tools are enabled
          if (toolsEnabled) {
            console.log("üîß Tools enabled, attempting routing for:", userMessage);
            const toolResult = await routeToAppropriateTools(userMessage);
            if (toolResult) {
              console.log("‚úÖ Tool result received:", toolResult);
              document.getElementById("response").innerText = toolResult.response;
              updateModelTitle("Tool", toolResult.toolName);
              return;
            }
            console.log("‚¨áÔ∏è No tool selected, falling back to LLM");
          } else {
            console.log("üîß Tools disabled, going directly to LLM");
          }
          
          // Fall back to LLM response if tools are disabled or no tool matched
          console.log("ü§ñ Making direct LLM call for:", userMessage);
          const response = await fetchLLMResponse(model.id, userMessage);
          console.log("‚úÖ LLM response received:", response);
          document.getElementById("response").innerText = response;
          updateModelTitle("LLM");
        } catch (error) {
          console.error("üí• Error in sendMessage:", error);
          document.getElementById("response").innerText = "Error: " + error.message;
          updateModelTitle("Error");
        }
      }

      // LLM-based tool router that analyzes user intent and selects appropriate tools
      async function routeToAppropriateTools(userMessage) {
        try {
          // Build tool descriptions for the LLM
          const toolDescriptions = availableTools.map(tool => 
            `${tool.name}: ${tool.description}`
          ).join('\n');

          // Create a prompt for tool selection
          const toolSelectionPrompt = `You are a tool router. Analyze the user's message and determine if it requires a specific tool.

Available tools:
get-forecast: Returns the current weather forecast for any location worldwide
get-time: Returns the current time, date, and timezone for any location worldwide

User message: "${userMessage}"

Respond with ONLY a JSON object in this exact format:
{
  "tool": "tool-name-here" or null,
  "location": "extracted-location" or null,
  "confidence": 0.0-1.0
}

Rules:
- Use "get-forecast" ONLY for explicit weather/forecast requests with a location
- Use "get-time" ONLY for explicit time/clock requests with a location
- Set tool to null for greetings, general questions, or any message without clear tool intent
- Extract the location mentioned in the message (city, country, etc.)
- Set confidence between 0.0 and 1.0 based on how certain you are
- Be conservative: when in doubt, set tool to null and confidence low

Examples:
- "hi" ‚Üí {"tool": null, "location": null, "confidence": 0.1}
- "hello" ‚Üí {"tool": null, "location": null, "confidence": 0.1}
- "what's the weather in Paris?" ‚Üí {"tool": "get-forecast", "location": "Paris", "confidence": 0.9}
- "current time in Tokyo" ‚Üí {"tool": "get-time", "location": "Tokyo", "confidence": 0.9}
- "tell me about physics" ‚Üí {"tool": null, "location": null, "confidence": 0.1}`;

          console.log("ü§ñ Calling LLM for tool routing with model:", model.id);
          console.log("üìù Tool selection prompt:", toolSelectionPrompt);
          
          const toolSelectionResponse = await fetchLLMResponse(model.id, toolSelectionPrompt);
          console.log("üîç LLM tool selection response:", toolSelectionResponse);
          
          // Parse the LLM response
          let toolSelection;
          try {
            // Extract JSON from the response (handle cases where LLM adds extra text)
            const jsonMatch = toolSelectionResponse.match(/\{[^{}]*\}/);
            if (!jsonMatch) {
              console.error("‚ùå No JSON found in LLM response:", toolSelectionResponse);
              throw new Error("No JSON found in response");
            }
            toolSelection = JSON.parse(jsonMatch[0]);
            console.log("‚úÖ Parsed tool selection:", toolSelection);
          } catch (parseError) {
            console.warn("‚ö†Ô∏è  Failed to parse tool selection response:", toolSelectionResponse);
            return null; // Fall back to LLM
          }          // Validate the tool selection
          if (!toolSelection.tool || toolSelection.confidence < 0.8) {
            console.log("üö´ Tool selection rejected - tool:", toolSelection.tool, "confidence:", toolSelection.confidence);
            return null; // Let LLM handle it
          }

          console.log("‚úÖ Tool selected:", toolSelection.tool, "with confidence:", toolSelection.confidence);

          // Find and execute the selected tool
          const selectedTool = availableTools.find(tool => tool.name === toolSelection.tool);
          if (!selectedTool) {
            console.warn("‚ùå Unknown tool selected:", toolSelection.tool);
            return null;
          }

          // Check if we have the required location parameter
          if (!toolSelection.location || toolSelection.location.trim() === "") {
            console.log("‚ùå No location extracted for tool:", toolSelection.tool);
            return null; // Fall back to LLM instead of showing error
          }

          console.log("üîß Executing tool:", selectedTool.name, "with location:", toolSelection.location);
          // Execute the tool
          const result = await selectedTool.execute(toolSelection.location);
          console.log("‚úÖ Tool result:", result);
          return {
            response: result,
            toolName: selectedTool.name
          };

        } catch (error) {
          console.error("üí• Error in LLM-based tool routing:", error);
          return null; // Fall back to LLM
        }
      }

      async function fetchLLMResponse(modelId, prompt) {
        console.log("üì° Making LLM API call to Ollama...");
        console.log("ü§ñ Model:", modelId);
        console.log("üìù Prompt:", prompt);
        
        try {
          const response = await fetch("http://localhost:11434/api/generate", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              model: modelId,
              prompt: prompt,
              stream: false
            })
          });

          console.log("üì° Ollama API response status:", response.status);
          
          if (!response.ok) {
            throw new Error(`Ollama API error: ${response.status}`);
          }

          const data = await response.json();
          console.log("‚úÖ Ollama API response data:", data);
          
          return data.response || "No response received.";
        } catch (error) {
          console.error("üí• Error in fetchLLMResponse:", error);
          throw error;
        }
      }

      // ============================================================================
      // TOOL HANDLERS AND DEFINITIONS
      // Add new tools here for easy maintenance
      // ============================================================================

      async function fetchWeather(location) {
        // Use the host machine's IP or localhost from the browser perspective
        const response = await fetch("http://localhost:5000/weather", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ location: location })
        });

        if (!response.ok) throw new Error("Weather API error");
        return await response.json();
      }

      async function fetchTime(location) {
        const response = await fetch("http://localhost:5000/time", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ location: location })
        });

        if (!response.ok) throw new Error("Time API error");
        return await response.json();
      }

      const availableTools = [
      {
        name: "get-forecast",
        description: "Returns the current weather forecast for any location worldwide",
        execute: async (location) => {
          const result = await fetchWeather(location);
          return `Weather in ${result.location}: ${result.forecast}`;
        }
      },
      {
        name: "get-time",
        description: "Returns the current time, date, and timezone for any location worldwide",
        execute: async (location) => {
          const result = await fetchTime(location);
          return `Current time in ${result.location}: ${result.time} on ${result.date} (${result.timezone})`;
        }
      }
      
      // Add new tools here
      // Example:
      // {
      //   name: "tool-name",
      //   description: "What the tool does - be descriptive for LLM understanding",
      //   execute: async (parameters) => {
      //     // Your tool execution code here
      //     // Parameters will be extracted by the LLM
      //   }
      // }
    ];
  </script>
</body>
</html>
